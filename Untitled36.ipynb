{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7402eb357e3b45189abe0a499e73a3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7914c71dd3394e4db6a6619dd80642c9",
              "IPY_MODEL_081c7235da06432bb378ed73a9e3fdde",
              "IPY_MODEL_dace338138224cf6a1e73f2c818af0ef"
            ],
            "layout": "IPY_MODEL_dd455d6fa603474db518a80b068384b5"
          }
        },
        "7914c71dd3394e4db6a6619dd80642c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffed6659ade8457a8912af873ddfe5b0",
            "placeholder": "​",
            "style": "IPY_MODEL_55b68d4174bf40d8b47d98b3b49920c2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "081c7235da06432bb378ed73a9e3fdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691825c486ef403e8dc74c5bedb9438d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d111d4a11fe4120bafe9f443bb3de66",
            "value": 2
          }
        },
        "dace338138224cf6a1e73f2c818af0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcbff57974942c58726ac7314579a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_7364f4c11b734cd885bbfcdc9bce8cca",
            "value": " 2/2 [01:13&lt;00:00, 34.11s/it]"
          }
        },
        "dd455d6fa603474db518a80b068384b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffed6659ade8457a8912af873ddfe5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b68d4174bf40d8b47d98b3b49920c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "691825c486ef403e8dc74c5bedb9438d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d111d4a11fe4120bafe9f443bb3de66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edcbff57974942c58726ac7314579a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7364f4c11b734cd885bbfcdc9bce8cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17prateek12/Generalized_LLM/blob/main/Untitled36.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSjKBWWADzNO"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.34.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "RC6MyDocIrvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58349955-6a10-42b9-dd89-afe84bbf9503"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "m0smfQWHSyIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da602eed-eaaf-455e-bc44-62e141de4e65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Using cached huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.34.0\n",
            "    Uninstalling transformers-4.34.0:\n",
            "      Successfully uninstalled transformers-4.34.0\n",
            "Successfully installed huggingface-hub-0.21.3 tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from datasets import load_dataset\n",
        "from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)"
      ],
      "metadata": {
        "id": "AXBP_DeGInWj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model= AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\",\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  offload_folder=\"offload\",\n",
        "  trust_remote_code=True,\n",
        "  low_cpu_mem_usage=True\n",
        ")\n",
        "llama_model.config.use_cache = False\n",
        "llama_model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "id": "soxGMr1wI5u4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "7402eb357e3b45189abe0a499e73a3b6",
            "7914c71dd3394e4db6a6619dd80642c9",
            "081c7235da06432bb378ed73a9e3fdde",
            "dace338138224cf6a1e73f2c818af0ef",
            "dd455d6fa603474db518a80b068384b5",
            "ffed6659ade8457a8912af873ddfe5b0",
            "55b68d4174bf40d8b47d98b3b49920c2",
            "691825c486ef403e8dc74c5bedb9438d",
            "9d111d4a11fe4120bafe9f443bb3de66",
            "edcbff57974942c58726ac7314579a4d",
            "7364f4c11b734cd885bbfcdc9bce8cca"
          ]
        },
        "outputId": "86b9e49e-92fb-4c56-802e-49039ca25164"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7402eb357e3b45189abe0a499e73a3b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = \"mistralai/Mistral-7B-v0.1\", trust_remote_code = True)\n",
        "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
        "llama_tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "-Thm95-7izPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = 128\n",
        "output_tokens = 128\n",
        "concurrency = 8"
      ],
      "metadata": {
        "id": "gSANjXxKj9sV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model.config.max_length = output_tokens\n",
        "llama_model.config.max_position_embeddings = input_tokens\n",
        "llama_tokenizer.model_max_length = input_tokens\n",
        "llama_tokenizer.max_len = output_tokens"
      ],
      "metadata": {
        "id": "KEa3G8KImvDg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation_pipeline = pipeline(\n",
        "  task=\"text-generation\",\n",
        "  tokenizer=llama_tokenizer,\n",
        "  model=llama_model,\n",
        "  torch_dtype=torch.float16,\n",
        "  max_length=output_tokens,\n",
        ")"
      ],
      "metadata": {
        "id": "hoLDSbycm9ps"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompts = [\"Please provide information about\", \"What is the meaning of\"]"
      ],
      "metadata": {
        "id": "9bGi2FB0nyc1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "yx6AWwGfn6Xw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens_processed = 0\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "Mk3eNEuQoB8o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for user_prompt in user_prompts * (concurrency // len(user_prompts)):\n",
        "    # Perform warm-up inference to potentially improve subsequent iterations\n",
        "    _ = text_generation_pipeline(user_prompt)\n",
        "\n",
        "    # Actual model inference\n",
        "    model_answer = text_generation_pipeline(user_prompt)\n",
        "    total_tokens_processed += input_tokens + output_tokens\n",
        "    print(f\"\\n[GENERATED_TEXT] {model_answer}\")"
      ],
      "metadata": {
        "id": "SM5pVFw5JM0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6016bf27-c0d8-45a6-b002-cf80bd09bdd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1339: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': \"Please provide information about the nature of the problem.\\n\\n## Answer (0)\\n\\nI'm not sure if this is the best way to do it, but I've found a solution.\\n\\nI've created a new class that inherits from `System.Windows.Forms.Form` and overrides the `OnPaint` method.\\n\\n```\\npublic class MyForm : Form\\n{\\n    protected override void OnPaint(PaintEventArgs e)\\n    {\\n        base.OnPaint(e);\\n\\n        // Draw your stuff here\\n    }\\n}\\n```\\n\"}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': 'What is the meaning of the word \"soul\"?\\n\\nThe word \"soul\" is used in many different ways. It is used to refer to the essence of a person, the part of a person that is immortal, and the part of a person that is responsible for moral and spiritual decisions. It is also used to refer to the part of a person that is responsible for emotions and feelings.\\n\\nThe word \"soul\" is also used to refer to the part of a person that is responsible for the body\\'s functions. This includes the heart, lungs, and other organs.\\n\\nThe'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': \"Please provide information about the nature of the problem.\\n\\n## Answer (0)\\n\\nI'm not sure if this is the best way to do it, but I've found a solution.\\n\\nI've created a new class that inherits from `System.Windows.Forms.Form` and overrides the `OnPaint` method.\\n\\n```\\npublic class MyForm : Form\\n{\\n    protected override void OnPaint(PaintEventArgs e)\\n    {\\n        base.OnPaint(e);\\n\\n        // Draw your stuff here\\n    }\\n}\\n```\\n\"}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': 'What is the meaning of the word \"soul\"?\\n\\nThe word \"soul\" is used in many different ways. It is used to refer to the essence of a person, the part of a person that is immortal, and the part of a person that is responsible for moral and spiritual decisions. It is also used to refer to the part of a person that is responsible for emotions and feelings.\\n\\nThe word \"soul\" is also used to refer to the part of a person that is responsible for the body\\'s functions. This includes the heart, lungs, and other organs.\\n\\nThe'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': \"Please provide information about the nature of the problem.\\n\\n## Answer (0)\\n\\nI'm not sure if this is the best way to do it, but I've found a solution.\\n\\nI've created a new class that inherits from `System.Windows.Forms.Form` and overrides the `OnPaint` method.\\n\\n```\\npublic class MyForm : Form\\n{\\n    protected override void OnPaint(PaintEventArgs e)\\n    {\\n        base.OnPaint(e);\\n\\n        // Draw your stuff here\\n    }\\n}\\n```\\n\"}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': 'What is the meaning of the word \"soul\"?\\n\\nThe word \"soul\" is used in many different ways. It is used to refer to the essence of a person, the part of a person that is immortal, and the part of a person that is responsible for moral and spiritual decisions. It is also used to refer to the part of a person that is responsible for emotions and feelings.\\n\\nThe word \"soul\" is also used to refer to the part of a person that is responsible for the body\\'s functions. This includes the heart, lungs, and other organs.\\n\\nThe'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': \"Please provide information about the nature of the problem.\\n\\n## Answer (0)\\n\\nI'm not sure if this is the best way to do it, but I've found a solution.\\n\\nI've created a new class that inherits from `System.Windows.Forms.Form` and overrides the `OnPaint` method.\\n\\n```\\npublic class MyForm : Form\\n{\\n    protected override void OnPaint(PaintEventArgs e)\\n    {\\n        base.OnPaint(e);\\n\\n        // Draw your stuff here\\n    }\\n}\\n```\\n\"}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[GENERATED_TEXT] [{'generated_text': 'What is the meaning of the word \"soul\"?\\n\\nThe word \"soul\" is used in many different ways. It is used to refer to the essence of a person, the part of a person that is immortal, and the part of a person that is responsible for moral and spiritual decisions. It is also used to refer to the part of a person that is responsible for emotions and feelings.\\n\\nThe word \"soul\" is also used to refer to the part of a person that is responsible for the body\\'s functions. This includes the heart, lungs, and other organs.\\n\\nThe'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elapsed_time = time.time() - start_time\n",
        "throughput = total_tokens_processed / elapsed_time"
      ],
      "metadata": {
        "id": "OxDMOJIGtAX9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTotal Throughput: {throughput} tokens/second\")"
      ],
      "metadata": {
        "id": "knEqvz4HtLGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60f8460-577c-4713-d599-c0593c41e890"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Throughput: 9.535091592672673 tokens/second\n"
          ]
        }
      ]
    }
  ]
}